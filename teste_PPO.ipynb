{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import time\n",
    "import numpy as np\n",
    "import platform\n",
    "import matplotlib.pyplot\n",
    "import torch\n",
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, VecVideoRecorder, VecTransposeImage\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.atari_wrappers import WarpFrame\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Space Size:  Box(0, 255, (96, 96, 3), uint8)\n",
      "Action Space Size:  Box([-1.  0.  0.], 1.0, (3,), float32)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CarRacing-v3')\n",
    "# env = DiscreteCarRacingWrapper(env)\n",
    "print(\"Observation Space Size: \", env.observation_space)\n",
    "print(\"Action Space Size: \", env.action_space)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_str = \"CarRacing-v3\"\n",
    "log_dir = \"./logs/{}\".format(env_str)\n",
    "env_kwargs_dict={\"continuous\": True}\n",
    "gray_scale = True\n",
    "\n",
    "# If gray_scale True, convert obs to gray scale 84 x 84 image\n",
    "wrapper_class = WarpFrame if gray_scale else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78be0a6f86e41c59d4293f6dc7bc2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -57.4    |\n",
      "| time/              |          |\n",
      "|    fps             | 50       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -51.7        |\n",
      "| time/                   |              |\n",
      "|    fps                  | 43           |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 94           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066630524 |\n",
      "|    clip_fraction        | 0.0659       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | -0.0161      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.213        |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    std                  | 0.999        |\n",
      "|    value_loss           | 0.635        |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Create Training CarRacing environment\n",
    "env_str = \"CarRacing-v3\"\n",
    "log_dir = \"./logs/{}\".format(env_str)\n",
    "env_kwargs_dict={\"continuous\": True}\n",
    "gray_scale = True\n",
    "\n",
    "# If gray_scale True, convert obs to gray scale 84 x 84 image\n",
    "wrapper_class = WarpFrame if gray_scale else None\n",
    "\n",
    "\n",
    "env = make_vec_env(env_str,\n",
    "                   n_envs=1,\n",
    "                   env_kwargs=env_kwargs_dict,\n",
    "                   wrapper_class=wrapper_class)\n",
    "env = VecFrameStack(env, n_stack=4)\n",
    "env = VecTransposeImage(env)\n",
    "\n",
    "# Create Evaluation CarRacing environment\n",
    "env_val = make_vec_env(env_str,\n",
    "                       n_envs=1,\n",
    "                       env_kwargs=env_kwargs_dict,\n",
    "                       wrapper_class=wrapper_class)\n",
    "env_val = VecFrameStack(env_val, n_stack=4)\n",
    "env_val = VecTransposeImage(env_val)\n",
    "\n",
    "# Create Evaluation Callback\n",
    "# eval_freq - can cause learning instability if set to low\n",
    "eval_callback = EvalCallback(env_val,\n",
    "                             best_model_save_path=log_dir,\n",
    "                             log_path=log_dir,\n",
    "                             eval_freq=25_000,\n",
    "                             render=False,\n",
    "                             n_eval_episodes=20)\n",
    "\n",
    "# Initialize DQN\n",
    "# buffer_size - encourages exploration of other actions\n",
    "model = PPO('CnnPolicy',\n",
    "            env,\n",
    "            verbose=1,\n",
    "            )\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=3000000,\n",
    "            progress_bar=True,\n",
    "            callback=eval_callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join(log_dir, \"ppo_car_racing\"))\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=20)\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "env.close()\n",
    "env_val.close()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
